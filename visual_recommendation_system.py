# -*- coding: utf-8 -*-
"""Visual Recommendation system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s8g4UJ4MrwEQbN_I7c7yKbF7OOwPe88x
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle

!kaggle datasets download -d paramaggarwal/fashion-product-images-dataset

!unzip /content/fashion-product-images-dataset.zip

!pip install swifter

#Importing Required Libraries
#CSV
import matplotlib.pyplot as plt
import plotly.express as px
import matplotlib.image as mpimg
import numpy as np
import pandas as pd
import os
import cv2

#Images
import keras
from keras import Model
import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from keras.layers import GlobalMaxPooling2D
tf.__version__

#Importing Dataset
Data = "/content/fashion-dataset"
print(os.listdir(Data))

df = pd.read_csv("/content/fashion-dataset/styles.csv", nrows=7000, on_bad_lines='skip')
df.head()

df.shape

df.info()

df.isnull().sum()

#Feature Engineering
df['image'] = df.apply(lambda row: str(row['id']) + ".jpg", axis=1)
df = df.reset_index(drop=True)
df.head(10)

df['articleType'].unique()

#Visualization
fig = px.bar(df.groupby('masterCategory').count().reset_index(), x='masterCategory',y='id',title='Count per Product Category')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})

fig = px.bar(df.groupby('subCategory').count().reset_index(), x='subCategory',y='id',title='Count per Product Sub-category', color='subCategory')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})

fig = px.bar(df.groupby('usage').count().reset_index(), x='usage', y='id', title='Count per Usage Category')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})

fig = px.bar(df.groupby('gender').count().reset_index(), x='gender', y='id', title='Count per Gender')
fig.update_layout(barmode='stack', xaxis={'categoryorder':'total descending'})

# Input Shape
img_width, img_height, _ = 224, 224, 3

# Pre-Trained Model
base_model = ResNet50(weights='imagenet',
                      include_top=False,
                      input_shape = (img_width, img_height, 3))
base_model.trainable = False

# Add Layer Embedding
model = keras.Sequential([
    base_model,
    GlobalMaxPooling2D()
])

model.summary()

#Defining Functions
def plot_figures(figures, *args, figsize=(16, 8), **kwargs):
    num_figures = len(figures)
    fig, axes = plt.subplots(1, num_figures, figsize=figsize)

    for ax, (title, img) in zip(axes, figures.items()):
        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        ax.set_title(title)
        ax.axis('off')

    plt.tight_layout()
    plt.show()

def img_path(img):
    return os.path.join(Data, "images", img)

def load_image(img, resized_fac=0.7):
    img_path = os.path.join(Data, "images", img)
    img = cv2.imread(img_path)
    w, h, _ = img.shape
    resized = cv2.resize(img, (int(h * resized_fac), int(w * resized_fac)), interpolation=cv2.INTER_CUBIC)
    return resized

def get_embedding(model, img_name):
    # Reshape
    img = image.load_img(img_path(img_name), target_size=(img_width, img_height))
    # img to Array
    x   = image.img_to_array(img)
    # Expand Dim (1, w, h)
    x   = np.expand_dims(x, axis=0)
    # Pre process Input
    x   = preprocess_input(x)
    return model.predict(x).reshape(-1)

# generation of a dictionary of (title, images)
figures = {'im'+str(i): load_image(row.image) for i, row in df.sample(6).iterrows()}

# plot of the images in a figure
plot_figures(figures, 2, 3)


%%time
import swifter
from tqdm import tqdm
tqdm.pandas()
 
def apply_get_embedding(img):
     try:
         return get_embedding(model, img)
     except Exception as e:
         # Handle the exception
         print(f"Skipping file {img} due to error: {e}")
         return None
 
df_embs = df['image'].swifter.apply(apply_get_embedding).progress_apply(pd.Series)
# 
# # Drop rows with missing embeddings
df_embs = df_embs.dropna()
#

#df_embs = pd.read_csv('embeddings_7k.csv', index_col=0)

df_embs.head()

df_embs.shape

df_embs.to_csv('embeddings_7k.csv')

from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

# Convert df_embs to a sparse matrix
sparse_embs = csr_matrix(df_embs.values)

# Calculate Cosine Similarity
cosine_sim = cosine_similarity(sparse_embs)

# The resulting cosine_sim matrix contains cosine similarity scores.
cosine_sim[:4, :4]

#USING EUCLIDEAN DISTANCE

from sklearn.metrics.pairwise import euclidean_distances

# Calculate Euclidean Distance
euclidean_dist = euclidean_distances(sparse_embs)

# The resulting euclidean_dist matrix contains Euclidean distance scores.
euclidean_dist[:4, :4]

indices = pd.Series(range(len(df)), index=df.index)

def get_recommender(idx, df, top_n = 5):
    sim_idx    = indices[idx]
    sim_scores = list(enumerate(cosine_sim[sim_idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]
    idx_rec    = [i[0] for i in sim_scores]
    idx_sim    = [i[1] for i in sim_scores]

    return indices.iloc[idx_rec].index, idx_sim

idx_ref = 6015

# Recommendations
idx_rec, idx_sim = get_recommender(idx_ref, df, top_n = 5)

# Plot
#===================
plt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))

# generation of a dictionary of (title, images)
figures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}
# plot of the images in a figure, with 2 rows and 3 columns
plot_figures(figures, 2, 3)

#REcommendation for Unseen data
from IPython.display import display, Image

def display_images(file_indices, img_files_list, top_n=5):
    for file in file_indices[:top_n]:
        img_name = img_files_list.iloc[file]
        img_path = os.path.join(Data, "images", img_name)  # Assuming images are in the 'images' directory
        print(img_path)

        # Use IPython.display to show images
        display(Image(filename=img_path, width=200, height=200))

# Image processing code for the unseen image
input_img_path = '/content/RLaver_shoe.jpg'
input_img = image.load_img(input_img_path, target_size=(224, 224))
input_img_array = image.img_to_array(input_img)
expand_input_img = np.expand_dims(input_img_array, axis=0)
preprocessed_input_img = preprocess_input(expand_input_img)
result_to_resnet_input = model.predict(preprocessed_input_img)
flatten_result_input = result_to_resnet_input.flatten()

# Convert df_embs to a sparse matrix
sparse_embs = csr_matrix(df_embs.values)

# Calculate Cosine Similarity with the input image features
cosine_sim_input = cosine_similarity(flatten_result_input.reshape(1, -1), sparse_embs)

# Get indices of top similar images
top_similar_indices = np.argsort(cosine_sim_input[0])[::-1][:5]

# Display reference image (unseen image)
plt.imshow(cv2.cvtColor(load_image(input_img_path), cv2.COLOR_BGR2RGB))
plt.title('Unseen Image (Reference)')
plt.axis('off')
plt.show()

# Display recommended images
display_images(top_similar_indices, df['image'], top_n=5)

#User Interface
gender_indices = {
    'Men': df[df['gender'] == 'Men'].index,
    'Women': df[df['gender'] == 'Women'].index,
    'Boys': df[df['gender'] == 'Boys'].index,
    'Unisex': df[df['gender'] == 'Unisex'].index,
    'Girls': df[df['gender'] == 'Girls'].index,
}

# Gender selection without using Streamlit
gender_options = list(gender_indices.keys())
selected_gender = input(f"Select Gender ({', '.join(gender_options)}): ").capitalize()
print(f"Selected Gender: {selected_gender}")

# Display indices for the selected gender
indicess = gender_indices[selected_gender]
print(f"Available Indices: {indicess}")

# Display indices for the selected gender
selected_index = input(f"Select Index ({', '.join(map(str, indicess))}): ")

# Validate the selected index
while not selected_index.isdigit() or int(selected_index) not in indicess:
    print("Invalid index. Please choose a valid index.")
    selected_index = input(f"Select Index ({', '.join(map(str, indicess))}): ")

selected_index = int(selected_index)

ref_img = load_image(df.iloc[selected_index].image)
plt.imshow(cv2.cvtColor(ref_img, cv2.COLOR_BGR2RGB))
plt.title('Reference Image')
plt.axis('off')
plt.show()

def recommend(idx, df, indices, top_n=5):
    try:
        sim_idx = indices.loc[idx]
    except KeyError:
        print(f"Index {idx} not found in the 'indices' object.")
        return pd.Index([]), []

    # The rest of your code remains the same...
    sim_scores = list(enumerate(cosine_sim[sim_idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n + 1]
    idx_rec = [i[0] for i in sim_scores]
    idx_sim = [i[1] for i in sim_scores]

    return indices.iloc[idx_rec], idx_sim